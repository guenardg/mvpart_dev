% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rpart-class.R
\docType{class}
\name{rpart-class}
\alias{rpart-class}
\alias{labels.rpart}
\alias{print.rpart}
\alias{prune.rpart}
\alias{predict.rpart}
\alias{residuals.rpart}
\alias{rsq.rpart}
\alias{plot.rpart}
\alias{summary.rpart}
\alias{text.rpart}
\alias{meanvar.rpart}
\title{Class and Methods for Recursive Partitioning and Regression Trees}
\format{
A \code{rpart-class} object contains:
\describe{
  \item{ frame }{ ... }
  \item{ where }{ ... }
  \item{ call }{ ... }
  \item{ terms }{ ... }
  \item{ cptable }{ ... }
  \item{ splits }{ ... }
  \item{ method }{ ... }
  \item{ dissim }{ ... }
  \item{ parms }{ ... }
  \item{ control }{ ... }
  \item{ functions }{ ... }
  \item{ y }{ ... }
  \item{ ordered }{ ... }
}
}
\usage{
\method{print}{rpart}(x, minlength = 0, spaces = 2, cp, digits = getOption("digits"), ...)

\method{labels}{rpart}(object, digits = 4, minlength = 1, pretty, collapse = TRUE, ...)

\method{prune}{rpart}(object, cp, ...)

\method{plot}{rpart}(
  x,
  uniform = FALSE,
  branch = 1,
  compress = FALSE,
  nspace,
  margin = 0,
  minbranch = 0.3,
  bar = 0.03,
  ...
)

\method{summary}{rpart}(object, cp = 0, digits = getOption("digits"), file, ...)

\method{predict}{rpart}(
  object,
  newdata = list(),
  type = c("vector", "prob", "class", "matrix", "where"),
  ...
)

\method{residuals}{rpart}(object, type = c("usual", "pearson", "deviance"), ...)

\method{rsq}{rpart}(x, ...)

\method{text}{rpart}(
  x,
  splits = TRUE,
  which = 4,
  label = "yval",
  FUN = text,
  all.leaves = FALSE,
  pretty = NULL,
  digits = getOption("digits") - 2,
  tadj = 0.65,
  stats = TRUE,
  use.n = FALSE,
  bars = TRUE,
  legend = FALSE,
  xadj = 1,
  yadj = 1,
  bord = FALSE,
  big.pts = FALSE,
  uniform = FALSE,
  branch = 1,
  nspace = -1,
  minbranch = 0.3,
  ...
)

\method{meanvar}{rpart}(object, xlab = "ave(y)", ylab = "ave(deviance)", ...)
}
\arguments{
\item{x}{Identical as argument \code{object}.}

\item{minlength}{The minimum length for abbreviation of character or factor
variables. If 0 no abbreviation is done; if 1 then single letters are used
with \code{"a"} for the first level, \code{"b"} for the second and so on. If
the value is greater than 1, the \code{abbreviate} function is used.}

\item{spaces}{The number of spaces to indent nodes of increasing depth.}

\item{cp}{Prune all nodes with a complexity less than \code{cp} from the
printout. Ignored if unspecified.}

\item{digits}{the number of digits to be used for numeric values. All of the
\code{rpart} functions that call labels explicitly set this value, with
\code{options("digits")} as the default.}

\item{...}{Optional arguments to be passed internally to other functions.}

\item{object}{An object of class \code{rpart}. This is assumed to be the
result of some function that produces an object with the same named
components as that returned by the \code{rpart} function.}

\item{pretty}{An argument included for backwards compatibility:
\code{pretty=0} implies \code{minlength=0}, \code{pretty=NULL} implies
\code{minlength=1}, and \code{pretty=TRUE} implies \code{minlength=4}. For
\code{text.rpart}: an integer denoting the extent to which factor levels in
split labels will be abbreviated.  A value of (0) signifies no abbreviation.
A \code{NULL}, the default, signifies using elements of letters to represent
the different factor levels.}

\item{collapse}{Whether the returned set of labels is always of the same
length as the number of nodes in the tree (logical). If \code{collapse=TRUE}
(default), the returned value is a vector of labels for the branch leading
into each node, with \code{"root"} as the label for the top node. If
\code{FALSE}, the returned value is a two column matrix of labels for the
left and right branches leading out from each node, with \code{"leaf"} as the
branch labels for terminal nodes.}

\item{uniform}{Uniform spacing of tree branches; default is \code{FALSE}.}

\item{branch}{Controls the shape of the branches from parent to child node.
Any number from 0 to 1 is allowed.  A value of 1 (the default) gives square
shouldered branches, a value of 0 give V shaped branches, with other values
being intermediate.}

\item{compress}{If \code{FALSE}, the leaf nodes will be at the horizontal
plot coordinates of \code{1:nleaves}. If \code{TRUE}, the routine attempts a
more compact arrangement of the tree. The compaction algorithm assumes
\code{uniform = TRUE}; surprisingly, the result is usually an improvement
even when that is not the case.}

\item{nspace}{The amount of extra space between a node with children and a
leaf, as compared to the minimal space between leaves. Applies to compressed
trees only. The default is the value of \code{branch}.}

\item{margin}{An extra percentage of white space to leave around the borders
of the tree. (Long labels sometimes get cut off by the default computation).}

\item{minbranch}{Set the minimum length for a branch to \code{minbranch}
times the average branch length. This parameter is ignored if
\code{uniform=TRUE}. Sometimes a split will give very little improvement, or
even (in the classification case) no improvement at all. A tree with branch
lengths strictly proportional to improvement leaves no room to squeeze in
node labels.}

\item{bar}{Length of bar at root (default = 0.03) -- used instead of char "|"}

\item{file}{Write the output to a given file name (Full listings of a tree
are often quite long).}

\item{newdata}{A data frame containing the values at which predictions are
required. The predictors referred to in the right side of
\code{formula(object)} must be present by name in \code{newdata}. If missing,
the fitted values are returned.}

\item{type}{A character string denoting the type of predicted or residual
values returned. For predictions, if the \code{rpart} object is a
classification tree, then the default is to return \code{prob} predictions,
a matrix whose columns are the probability of the first, second, etc. class.
(This agrees with the default behavior of tree).  Otherwise, a vector of the
results is returned. For residuals, in the case of a regression or anova
tree, all three residual definitions reduce to \code{y - fitted}. This is the
residual returned for \code{user} method trees as well. For classification
trees the \code{usual} residuals are the missclassification losses L(actual,
predicted) where L is the loss matrix.  With default losses this residual is
0/1 for correct/incorrect classification. The \code{pearson} residual is
(1 - fitted)/sqrt(fitted(1 - fitted)) and the \code{deviance} residual is
sqrt(minus twice logarithm of fitted). For \code{poisson} and \code{exp} (or
survival) trees, the \code{usual} residual is the observed - expected number
of events. The \code{pearson} and \code{deviance} residuals are as defined in
McCullagh and Nelder.}

\item{splits}{logical flag. If \code{TRUE} (default), then the splits in the
tree are labelled with the criterion for the split.}

\item{which}{labels splits 1 = centre, 2 = left, 3 = right , 4 = both.}

\item{label}{A column name of \code{x$frame};  values of this will label the
nodes.  For the \code{"class"} method, \code{label="yval"} results in the
factor levels being used, \code{"yprob"} results in the probability of the
winning factor level being used, and 'specific yval level' results in the
probability of that factor level.}

\item{FUN}{The name of a labelling function, e.g. \code{text}.}

\item{all.leaves}{Logical. If \code{TRUE}, all nodes are labelled, otherwise
just terminal nodes.}

\item{tadj}{Adjustment of text above (or below) splits.}

\item{stats}{If \code{TRUE} adds statistics to nodes.}

\item{use.n}{If \code{TRUE} adds N to labels. (\#events level1/ \#events
level2/etc. for \code{class}, \code{n} for \code{anova}, and \#events/n for
\code{poisson} and \code{exp}).}

\item{bars}{If \code{TRUE} adds barplots for multivariate regression trees.}

\item{legend}{If \code{TRUE} adds legends for multivariate regression trees.}

\item{xadj}{varies the horizontal size of barplots for multivariate
regression trees.}

\item{yadj}{varies the vertical size of barplots for multivariate
regression trees.}

\item{bord}{Adds borders (boxes) to barplots for multivariate regression
trees.}

\item{big.pts}{Adds color coded points to nodes. Useful to track groups to
PCA plot (see \code{rpart.pca}).}

\item{xlab}{The x-axis label for the plot.}

\item{ylab}{The y-axis label for the plot.}
}
\value{
The returned value depends on the method:
\describe{
  \item{labels.rpart}{ A vector of split labels (\code{collapse=TRUE}) or
  matrix of left and right splits (\code{collapse=FALSE}) for the supplied
  \code{rpart} object.  This function is called by printing methods for
  \code{rpart} and is not intended to be called directly by the users. }
  \item{plot.rpart}{The coordinates of the nodes are returned as a list, with
  components \code{x} and \code{y}.}
  \item{predict.rpart}{A new object is obtained by dropping \code{newdata}
  down the object. For factor predictors, if an observation contains a level
  not used to grow the tree, it is left at the deepest possible node and
  \code{frame$yval} at the node is the prediction.
  
  If \code{type="vector"}:\cr
  a vector of predicted responses. For regression trees this is the mean
  response at the node, for Poisson trees it is the estimated response rate,
  and for classification trees it is the predicted class.
  
  If \code{type="prob"}:\cr
  (for a classification tree) a matrix of class probabilities.
  
  If \code{type="matrix"}:\cr
  a matrix of the full responses (\code{frame$yval2} if this exists,
  otherwise \code{frame$yval}). For regression trees, this is the mean
  response, for Poisson trees it is the response rate and the number of
  events at that node in the fitted tree, and for classification trees it is
  the concatonation of the predicted class, the class counts at that node in
  the fitted tree, and the class probabilities.
  
  If \code{type="class"}:\cr
  (for a classification tree) a factor of classifications based on the
  responses.
  }
  \item{fitted.rpart}{A vector of residuals of type \code{type} from an
  \code{rpart} object.}
  \item{text.rpart}{\code{NULL} (invisibly).}
  \item{meanvar.rpart}{An invisible list containing the following vectors: x,
  fitted value at terminal nodes (\code{yval}); y, deviance of node divided
  by number of observations at node; and label, the node numbers.}
}
}
\description{
Class and methods to handle an \code{rpart} model.
}
\details{
\describe{
  \item{print.rpart}{This function is a method for the generic function
  \code{print} for class \code{"rpart"}.  It can be invoked by calling print
  for an object of the appropriate class, or directly by calling
  \code{print.rpart} regardless of the class of the object. Side effects: A
  semi-graphical layout of the contents of \code{x$frame} is printed.
  Indentation is used to convey the tree topology. Information for each node
  includes the node number, split, size, deviance, and fitted value.  For the
  \code{"class"} method, the class probabilties are also printed.}
  \item{plot.rpart}{This function is a method for the generic function
  \code{plot}, for objects of class \code{rpart}. The y-coordinate of the top
  node of the tree will always be 1. Side effects: an unlabeled plot is
  produced on the current graphics device.}
  \item{summary.rpart}{This function is a method for the generic function
  summary for class \code{"rpart"}.  It can be invoked by calling
  \code{summary} for an object of the appropriate class, or directly by
  calling \code{summary.rpart} regardless of the class of the object.}
  \item{predict.rpart}{This function is a method for the generic function
  predict for class \code{rpart}. It can be invoked by calling \code{predict}
  for an object of the appropriate class, or directly by calling
  \code{predict.rpart} regardless of the class of the object. }
  \item{rsq.rpart}{Two plots are produced. The labels are only appropriate
  for the \code{"anova"} method.}
}
}
\section{Functions}{
\itemize{
\item \code{print(rpart)}: Print an Rpart Object

This function prints an \code{rpart} object. It is a method for the generic
function \code{print} of class \code{rpart}.

\item \code{labels(rpart)}: Create Split Labels For an Rpart Object

This function provides labels for the branches of an \code{rpart} tree.

\item \code{prune(rpart)}: Cost-complexity Pruning of an Rpart Object

Determines a nested sequence of subtrees of the supplied \code{rpart} object
by recursively \code{snipping} off the least important splits, based on the
complexity parameter (\code{cp}).

\item \code{plot(rpart)}: Plot an Rpart Object

Plots an rpart object on the current graphics device.

\item \code{summary(rpart)}: Summarize an Rpart Object

Returns a detailed listing of an \code{rpart} object.

\item \code{predict(rpart)}: Predictions from a Fitted Rpart Object

Returns a vector of predicted responses from a fitted \code{rpart} object.

\item \code{residuals(rpart)}: Residuals From a Fitted Rpart Object

Method for \code{residuals} for an \code{rpart} object.

\item \code{rsq(rpart)}: Plots the Approximate R-Square for the Different Splits

Produces 2 plots.  The first plots the r-square (apparent and apparent - from
cross-validation) versus the number of splits. The second plots the Relative
Error(cross-validation) +/- 1-SE from cross-validation versus the number of
splits.

\item \code{text(rpart)}: Place Text on a Dendrogram

Labels the current plot of the tree dendrogram with text.

\item \code{meanvar(rpart)}: Mean-Variance Plot for an Rpart Object

Creates a plot on the current graphics device of the deviance of the node
divided by the number of observations at the node.  Also returns the node
number.

}}
\examples{
## print.rpart

data(car.test.frame)
z.auto <- rpart(Mileage ~ Weight, car.test.frame)
z.auto

## plot.rpart
data(car.test.frame)
fit <- rpart(Price ~ Mileage + Type + Country, car.test.frame)
plot(fit, compress=TRUE)

## summary.rpart
data(car.test.frame)
z.auto <- rpart(Mileage ~ Weight, car.test.frame)
summary(z.auto)

## predict.rpart:
data(car.test.frame)
z.auto <- rpart(Mileage ~ Weight, car.test.frame)
predict(z.auto)

data(kyphosis)
fit <- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis)
predict(fit, type="prob")   # class probabilities (default)
predict(fit, type="vector") # level numbers
predict(fit, type="class")  # factor
predict(fit, type="matrix") # level number, class frequencies, probabilities

data(iris)
sub <- c(sample(1:50, 25), sample(51:100, 25), sample(101:150, 25))
fit <- rpart(Species ~ ., data=iris, subset=sub)
fit
table(predict(fit, iris[-sub,], type="class"), iris[-sub, "Species"])

## residuals.rpart:
data(solder)
fit <- rpart(skips ~ Opening + Solder + Mask + PadType + Panel,
             data = solder, method='anova')
summary(residuals(fit))
plot(predict(fit),residuals(fit))

# example code
data(car.test.frame)
z.auto <- rpart(Mileage ~ Weight, car.test.frame)
rsq(z.auto)

## text.rpart
data(car.test.frame)
z.auto <- rpart(Mileage ~ Weight, car.test.frame)
plot(z.auto)
text(z.auto, use.n=TRUE, all=TRUE)

## meanvar.rpart
data(car.test.frame)
z.auto <- rpart(Mileage ~ Weight, car.test.frame)
meanvar(z.auto, log='xy')

}
\references{
McCullagh P. and Nelder, J. A. (1989) Generalized Linear Models. London:
Chapman and Hall.
}
